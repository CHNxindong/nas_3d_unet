{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haha\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    np.load('a')\n",
    "except FileNotFoundError:\n",
    "    print('haha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import nibabel as nib\n",
    "import os\n",
    "import glob\n",
    "from dev_tools.my_tools import print_red, minmax_normalize\n",
    "import pdb\n",
    "import numpy as np\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "\n",
    "def create_h5(source_folder, mean_std_file, overwrite=False):\n",
    "    try:\n",
    "        affine = np.load('data/affine.npy')\n",
    "    except FileNotFoundError:\n",
    "        affine = None\n",
    "    \n",
    "    target = os.path.join('data',source_folder.split('_')[-1]+'.h5')\n",
    "    \n",
    "    if os.path.exists(target) and not overwrite:\n",
    "        print('{:s} exists already.'.format(target))\n",
    "        return\n",
    "    \n",
    "    with open(mean_std_file,'rb') as f:\n",
    "        mean_std_values = pickle.load(f)\n",
    "    \n",
    "    with h5py.File(target,'w') as f:\n",
    "        img_dirs  = glob.glob(os.path.join(source_folder,'*/*' \n",
    "                                             if source_folder.split('_')[-1] == 'Training' else '*'))\n",
    "        for img_dir in tqdm(img_dirs,desc='writing {:s}'.format(target)):\n",
    "            if not os.path.isdir(img_dir):\n",
    "                continue\n",
    "            sub_id = img_dir.split('/')[-1]\n",
    "            h5_subid = f.create_group(sub_id)\n",
    "            brain_widths = []\n",
    "            for mod_file in os.listdir(img_dir):\n",
    "                img = nib.load(os.path.join(img_dir,mod_file))\n",
    "                if affine is None:\n",
    "                    affine = img.affine\n",
    "                    np.save('data/affine',affine)\n",
    "                img_npy = img.get_data()\n",
    "                mod = mod_file.split('_')[-1].split('.')[0]\n",
    "                if mod != 'seg':\n",
    "                    img_npy = normalize(img_npy,\n",
    "                                        mean = mean_std_values['{:s}_mean'.format(mod)],\n",
    "                                        std = mean_std_values['{:s}_std'.format(mod)])\n",
    "                    brain_widths.append(cal_outline(img_npy))\n",
    "                h5_subid.create_dataset(mod_file,data=img_npy)\n",
    "            start_edge = np.min(brain_widths,axis=0)[0]\n",
    "            end_edge = np.max(brain_widths,axis=0)[1]\n",
    "            brain_width = np.vstack((start_edge,end_edge))\n",
    "            h5_subid.create_dataset('brain_width',data=brain_width)\n",
    "    return\n",
    "\n",
    "def cal_outline(img_npy):\n",
    "    '''\n",
    "    return an numpy array shape=(2,3), indicating the outline of the brain area.\n",
    "    '''\n",
    "    brain_index = np.asarray(np.nonzero(img_npy))\n",
    "    start_edge = np.maximum(np.min(brain_index,axis=1)-1,0)\n",
    "    end_edge = np.minimum(np.max(brain_index,axis=1)+1,img_npy.shape)\n",
    "    \n",
    "    return np.vstack((start_edge,end_edge))\n",
    "\n",
    "def normalize(img_npy,mean,std,offset=0.1, mul_factor=100):\n",
    "    '''\n",
    "    offset and mul_factor are used to make a distinction between brain voxel and background(zeros).\n",
    "    '''\n",
    "    brain_index = np.nonzero(img_npy)\n",
    "    img_npy[brain_index] = (minmax_normalize((img_npy[brain_index]-mean)/std) + offset) * mul_factor\n",
    "    return img_npy\n",
    "\n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flair_mean': 415.9545,\n",
       " 'flair_std': 1246.5544,\n",
       " 't1_mean': 574.6952,\n",
       " 't1_std': 1102.1575,\n",
       " 't1ce_mean': 643.7283,\n",
       " 't1ce_std': 1123.4411,\n",
       " 't2_mean': 657.6712,\n",
       " 't2_std': 1307.7268}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/mean_std.pkl','rb') as f:\n",
    "    a = pickle.load(f)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cal_mean_std(source_folder,saved_path,overwrite=False):\n",
    "    '''\n",
    "    Calculte the mean value and standard deviation for each modalities.\n",
    "    Return a dictionary {'t1_mean': ,'t1_std': ,'t2_mean': ,'t2_std': ,...}\n",
    "    '''\n",
    "    if os.path.exists(saved_path) and not overwrite:\n",
    "        print('{:s} exists already.'.format(saved_path))\n",
    "        return\n",
    "    sub_dirs = glob.glob(os.path.join(source_folder,'*/*')) # SD\n",
    "    \n",
    "    mean_std_values = {}\n",
    "    \n",
    "    for mod in config['data']['all_mods']:\n",
    "        mean = 0\n",
    "        amount = 0\n",
    "        for sub_dir in tqdm(sub_dirs,\n",
    "                             desc='Calculating {:s}\\'s mean value'\n",
    "                             .format(mod)):\n",
    "            file_name = os.path.join(sub_dir,sub_dir.split('/')[-1]+'_{:s}.nii.gz'.format(mod))\n",
    "            img_npy = nib.load(file_name).get_data()\n",
    "            brain_area = img_npy[np.nonzero(img_npy)]\n",
    "            mean += np.sum(brain_area)\n",
    "            amount += len(brain_area)\n",
    "        mean /= amount\n",
    "        mean_std_values['{:s}_mean'.format(mod)] = round(mean,4)\n",
    "        print('{:s}\\'s mean value = {:.2f}'.format(mod,mean))\n",
    "        \n",
    "        std = 0\n",
    "        for sub_dir in tqdm(sub_dirs,\n",
    "                             desc='Calculating {:s}\\'s std value'\n",
    "                             .format(mod)):\n",
    "            file_name = os.path.join(sub_dir,sub_dir.split('/')[-1]+'_{:s}.nii.gz'.format(mod))\n",
    "            img_npy = nib.load(file_name).get_data()\n",
    "            brain_area = img_npy[np.nonzero(img_npy)]\n",
    "            std += np.sum((brain_area-mean)**2)\n",
    "        std = np.sqrt(std/amount)\n",
    "        mean_std_values['{:s}_std'.format(mod)] = round(std,4)\n",
    "        print('{:s}\\'s std value = {:.2f}'.format(mod,std))\n",
    "    print(mean_std_values)\n",
    "    with open(saved_path,'wb') as f:\n",
    "        pickle.dump(mean_std_values,f)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/mean_std.pkl exists already.\n",
      "data/Training.h5 exists already.\n",
      "data/Validation.h5 exists already.\n",
      "data/Testing.h5 exists already.\n"
     ]
    }
   ],
   "source": [
    "with open('config.yml') as f:\n",
    "    config = yaml.load(f,Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "cal_mean_std(source_folder=config['data']['source_train'],\n",
    "             saved_path=config['data']['mean_std_file'])\n",
    "\n",
    "mean_std_file = config['data']['mean_std_file']\n",
    "create_h5(config['data']['source_train'],mean_std_file)\n",
    "create_h5(config['data']['source_val'],mean_std_file)\n",
    "create_h5(config['data']['source_test'],mean_std_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534.3123637025672"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = nib.load('data/MICCAI_BraTS_2019_Data_Training/HGG\\\n",
    "/BraTS19_TMC_11964_1/BraTS19_TMC_11964_1_t1.nii.gz').get_data()\n",
    "np.mean(np.ravel(img)[np.flatnonzero(img)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534.3123637025672"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = img[np.nonzero(img)]\n",
    "np.sum(b)/len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a':1,'b':2}\n",
    "with open('test.pkl','wb') as f:\n",
    "    pickle.dump(a,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t1_std': 1082.5379, 't1_mean': 571.9798, 't1ce_std': 1093.0112, 't2_mean': 652.5108, 'flair_mean': 411.4047, 't2_std': 1285.4105, 'flair_std': 1219.138, 't1ce_mean': 637.505}\n"
     ]
    }
   ],
   "source": [
    "with open('data/mean_std.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1,2,3,50,34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.916666666666664"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([np.mean([1,34]),np.mean([2,3,50])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
