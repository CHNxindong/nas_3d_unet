{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pdb\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from search import Searching\n",
    "from math import ceil, floor\n",
    "import collections\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search = Searching()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test():\n",
    "#     pdb.set_trace()\n",
    "    x = torch.randn(1, 8, 4, 4, 4)\n",
    "    x = torch.as_tensor(x, device=torch.device('cuda'))\n",
    "    dilation = 2\n",
    "    kernel_size = 1\n",
    "    stride = 1\n",
    "    padding = max(0, ceil((dilation * (kernel_size - 1) - stride + 1)/2))\n",
    "    m1 = nn.Conv3d(8, 8, kernel_size,stride=stride, padding=padding, dilation=dilation).to('cuda')\n",
    "    padding = max(0, ceil((dilation * (kernel_size - 1) - stride + 1)/2))\n",
    "    m2 = nn.ConvTranspose3d(8, 8, kernel_size, stride=stride, padding=padding, dilation=dilation, output_padding=0).to('cuda')\n",
    "    y1 = m1(x)\n",
    "    print(y1.shape)\n",
    "    y2 = m2(y1)\n",
    "    print(y2.shape)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(9,5)\n",
    "a2 = torch.randn(9,5)\n",
    "b = torch.randn(9,6)\n",
    "c = torch.randn(9,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('down_se_conv', 0), ('max_pool', 1), ('dep_conv', 2), ('down_se_conv', 1), ('down_dep_conv', 1), ('se_conv', 3)] [('identity', 0), ('up_se_conv', 1), ('dil_conv', 2), ('conv', 0), ('dep_conv', 0), ('dep_conv', 2)]\n",
      "[('down_se_conv', 0), ('max_pool', 1), ('dep_conv', 2), ('down_se_conv', 1), ('down_dep_conv', 1), ('se_conv', 3)] [('identity', 0), ('up_se_conv', 1), ('dil_conv', 2), ('conv', 0), ('dep_conv', 0), ('dep_conv', 2)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1_down = F.softmax(a, dim=-1).detach().cpu().numpy()\n",
    "a1_up = F.softmax(a2, dim=-1).detach().cpu().numpy()\n",
    "a2_down = F.softmax(b, dim=-1).detach().cpu().numpy()\n",
    "a2_up = F.softmax(c, dim=-1).detach().cpu().numpy()\n",
    "from genotype import Genotype, GenoParser\n",
    "gp = GenoParser()\n",
    "db = gp.parse(a1_down, a2_down, cell_type='down')\n",
    "ub = gp.parse(a1_up, a2_up, cell_type='up')\n",
    "print(db,ub)\n",
    "mydb = gp.my_parse(a1_down, a2_down)\n",
    "myub = gp.my_parse(a1_up, a2_up, downward=False)\n",
    "print(mydb,myub)\n",
    "mydb == db, myub == ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('down_se_conv', 0), ('max_pool', 1), ('dep_conv', 2), ('down_se_conv', 1), ('down_dep_conv', 1), ('se_conv', 3)] [('identity', 0), ('up_se_conv', 1), ('dil_conv', 2), ('conv', 0), ('dep_conv', 0), ('dep_conv', 2)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1_down = F.softmax(a, dim=-1).detach().cpu().numpy()\n",
    "a1_up = F.softmax(a2, dim=-1).detach().cpu().numpy()\n",
    "a2_down = F.softmax(b, dim=-1).detach().cpu().numpy()\n",
    "a2_up = F.softmax(c, dim=-1).detach().cpu().numpy()\n",
    "from genotype import Genotype, GenoParser\n",
    "gp = GenoParser(3)\n",
    "\n",
    "mydb = gp.parse(a1_down, a2_down)\n",
    "myub = gp.parse(a1_up, a2_up, downward=False)\n",
    "print(mydb,myub)\n",
    "mydb == db, myub == ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'a'), (2, 'c'), (3, 'b')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [(1,('a')),(3,('b')),(2,('c'))]\n",
    "a.sort()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    " \n",
    "formatter = logging.Formatter('%(message)s')\n",
    "# Configure stream handler for the cells\n",
    "chandler = logging.StreamHandler()\n",
    "# chandler.setLevel(logging.INFO)\n",
    "chandler.setFormatter(formatter)\n",
    " \n",
    "# Add both handlers\n",
    "logger.addHandler(chandler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    " \n",
    "# Show the handlers\n",
    "# logger.handlers\n",
    " \n",
    "# Log Something\n",
    "logger.info(\"Test info\")\n",
    "logger.debug(\"Test debug\")\n",
    "logger.error(\"Test error\")\n",
    "while logger.handlers:\n",
    "    logger.handlers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import generator\n",
    "from dev_tools.my_tools import print2d\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "def test():\n",
    "#     pdb.set_trace()\n",
    "    temp = time.time()\n",
    "    dataset = generator.Dataset()\n",
    "    train = dataset.train_generator\n",
    "    val = dataset.val_generator\n",
    "    epoch = val.epoch()\n",
    "    for i,(x,y) in tqdm(enumerate(epoch),total = val.steps_per_epoch):\n",
    "#         pass\n",
    "        return torch.as_tensor(x,device=torch.device('cuda')),torch.as_tensor(y,device=torch.device('cuda'))\n",
    "        \n",
    "    print(time.time() - temp)\n",
    "x,y = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "device = torch.device('cuda')\n",
    "a = torch.Tensor(x)\n",
    "b = torch.from_numpy(x)\n",
    "b[0,0] = 1000\n",
    "c = torch.as_tensor(x,device=device)\n",
    "# b = b.cuda()\n",
    "# print(a.dtype,b.dtype)\n",
    "# c.device\n",
    "# b.device\n",
    "# b.cuda()\n",
    "# c = torch.Tensor(2,3)\n",
    "# c.cuda()\n",
    "print(a,b,c)\n",
    "a = a.cuda()\n",
    "print(a)\n",
    "b = b.to(device)\n",
    "print(b)\n",
    "b[0,0] = 100\n",
    "c[0,0] = 100\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = np.random.randint(2, size = (2,3,128,128,128))\n",
    "# a = tf.constant(x,dtype = float)\n",
    "# with tf.Session() as s:\n",
    "#     print(dice_coefficient(a,a).eval())\n",
    "axis=(-1,-2,-3)\n",
    "smooth=0.00001\n",
    "#     temp = (2*K.sum(a * a, axis=axis) + smooth)/(K.sum(a, axis=axis) + K.sum(a,axis=axis) + smooth)\n",
    "#     print(temp.eval())\n",
    "#     print(K.mean(temp).eval())\n",
    "x = torch.as_tensor(a, device=torch.device('cuda'))\n",
    "xx = torch.as_tensor(a, device = torch.device('cpu'))\n",
    "import loss\n",
    "w_dice = loss.WeightedDiceLoss()\n",
    "w_dice(x, y).device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yml') as f:\n",
    "    config = yaml.load(f,Loader=yaml.FullLoader)\n",
    "    print(config['data'])\n",
    "with open('a.yml','w') as f:\n",
    "    yaml.dump({'a':[1,2,3]},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "class test():\n",
    "    def __init__(self):\n",
    "        self.h5_f = h5py.File('data/training.h5','r')\n",
    "    def hello(self):\n",
    "        print(len(list(self.h5_f.keys())))\n",
    "    def end(self):\n",
    "        self.h5_f.close()\n",
    "t = test()\n",
    "t.hello()\n",
    "t.end()\n",
    "t.__init__()\n",
    "t.hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# temp = time.time()\n",
    "# print(patching_autofit((240,240,155),(128,128,128)))\n",
    "# print(time.time()-temp)\n",
    "# temp = time.time()\n",
    "# print(patching_hardcode128((240,240,155),(128,128,128)))\n",
    "# print(time.time()-temp)\n",
    "# print(patching((240,240,155),(128,128,128)))\n",
    "\n",
    "# print(np.vstack((a,b)))\n",
    "print('\\n')\n",
    "print(patching((240,240,155),(128,128,128)))\n",
    "print('\\n')\n",
    "print(patching((240,240,155),(128,128,128),overlap=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float('inf') == float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array([8,6+12]) -18) % 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a':1,'b':2}\n",
    "with open('test.pkl','wb') as f:\n",
    "    pickle.dump(a,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/mean_std.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([1,2,3,50,34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([np.mean([1,34]),np.mean([2,3,50])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
