{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from search import Searching\n",
    "from train import Training\n",
    "from prediction import Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = Searching()\n",
    "gene = s.search()\n",
    "\n",
    "t = Training()\n",
    "t.main_run()\n",
    "\n",
    "# t = Training(for_final_training=True)\n",
    "# t.main_run()\n",
    "\n",
    "p = Prediction()\n",
    "p.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "sd = torch.load('BACKUP/first_training_drop0.1/last_train.pt')\n",
    "his = sd['history']\n",
    "loss = his['loss']\n",
    "val_loss = his['val_loss']\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(range(len(loss)), loss, label='loss')\n",
    "plt.plot(range(len(loss)), val_loss, label='val_loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Weighted Dice Loss')\n",
    "plt.legend()\n",
    "plt.savefig('log/training_log.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = torch.load('log/last_search.pt')\n",
    "his = sd['history']\n",
    "shell_loss = his['shell_loss']\n",
    "kernel_loss = his['kernel_loss']\n",
    "val_loss = his['val_loss']\n",
    "n = range(len(shell_loss))\n",
    "plt.plot(n, shell_loss, label='shell_loss')\n",
    "plt.plot(n, kernel_loss, label='kernel_loss')\n",
    "plt.plot(n, val_loss, label='val_loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Weighted Dice Loss')\n",
    "plt.legend()\n",
    "plt.savefig('log/searching_log.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = np.load('../brats2019/demo_lite_test/demo_task1/temp.npy')\n",
    "patch_indices = np.asarray([[ 0,  0,  0],\n",
    "       [ 6,  0,  0],\n",
    "       [ 0, 54,  0],\n",
    "       [ 0,  0, 12],\n",
    "       [ 6, 54,  0],\n",
    "       [ 6, 54, 12],\n",
    "       [ 6,  0, 12],\n",
    "       [ 0, 54, 12],\n",
    "       [ 3, 27,  6]])\n",
    "data_shape=[3, 134, 182, 140]\n",
    "from patches import reconstruct_from_patches, stitch\n",
    "img1 = reconstruct_from_patches(patches, patch_indices, data_shape)\n",
    "img2 = stitch(patches, patch_indices, data_shape)\n",
    "np.sum(img1[0] != img2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev_tools.my_tools import print2d\n",
    "print2d(img1[0])\n",
    "print2d(img2[0])\n",
    "print2d(img2[0]*(img1[0] != img2[0]))\n",
    "print2d(img1[0]*(img1[0] != img2[0]))\n",
    "np.sum(np.round(img1[img1!= img2]-img2[img1!=img2], 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(1.234,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(g.down, \n",
    "          'log/db', \n",
    "          'Downward Block')\n",
    "visualize(g.up, \n",
    "          'log/ub', \n",
    "          'Upward Block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        self.x = 1\n",
    "        self.p()\n",
    "    def p(self):\n",
    "        print('A')\n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def p(self):\n",
    "        pass\n",
    "\n",
    "B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(9,5)\n",
    "a2 = torch.randn(9,5)\n",
    "b = torch.randn(9,6)\n",
    "c = torch.randn(9,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_down = F.softmax(a, dim=-1).detach().cpu().numpy()\n",
    "a1_up = F.softmax(a2, dim=-1).detach().cpu().numpy()\n",
    "a2_down = F.softmax(b, dim=-1).detach().cpu().numpy()\n",
    "a2_up = F.softmax(c, dim=-1).detach().cpu().numpy()\n",
    "from genotype import Genotype, GenoParser\n",
    "gp = GenoParser()\n",
    "db = gp.parse(a1_down, a2_down, cell_type='down')\n",
    "ub = gp.parse(a1_up, a2_up, cell_type='up')\n",
    "print(db,ub)\n",
    "mydb = gp.my_parse(a1_down, a2_down)\n",
    "myub = gp.my_parse(a1_up, a2_up, downward=False)\n",
    "print(mydb,myub)\n",
    "mydb == db, myub == ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_down = F.softmax(a, dim=-1).detach().cpu().numpy()\n",
    "a1_up = F.softmax(a2, dim=-1).detach().cpu().numpy()\n",
    "a2_down = F.softmax(b, dim=-1).detach().cpu().numpy()\n",
    "a2_up = F.softmax(c, dim=-1).detach().cpu().numpy()\n",
    "from genotype import Genotype, GenoParser\n",
    "gp = GenoParser(3)\n",
    "\n",
    "mydb = gp.parse(a1_down, a2_down)\n",
    "myub = gp.parse(a1_up, a2_up, downward=False)\n",
    "print(mydb,myub)\n",
    "mydb == db, myub == ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen():\n",
    "    for i in range(20):\n",
    "        yield i\n",
    "g = gen()\n",
    "st = time.time()\n",
    "desc = 'epoch {}'.format(0)\n",
    "with tqdm(g,total=20,desc=desc) as t:\n",
    "    for step, x in enumerate(t):\n",
    "        time.sleep(0.1)\n",
    "        info = collections.OrderedDict()\n",
    "        info['AShellLoss'] = '{:03d}'.format(step)\n",
    "        info['KernelLoss'] = x\n",
    "        t.set_postfix(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = collections.OrderedDict()\n",
    "d['K'] = 1\n",
    "d['A'] = 2\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    " \n",
    "formatter = logging.Formatter('%(message)s')\n",
    "# Configure stream handler for the cells\n",
    "chandler = logging.StreamHandler()\n",
    "# chandler.setLevel(logging.INFO)\n",
    "chandler.setFormatter(formatter)\n",
    " \n",
    "# Add both handlers\n",
    "logger.addHandler(chandler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    " \n",
    "# Show the handlers\n",
    "# logger.handlers\n",
    " \n",
    "# Log Something\n",
    "logger.info(\"Test info\")\n",
    "logger.debug(\"Test debug\")\n",
    "logger.error(\"Test error\")\n",
    "while logger.handlers:\n",
    "    logger.handlers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import generator\n",
    "from dev_tools.my_tools import print2d\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "def test():\n",
    "#     pdb.set_trace()\n",
    "    temp = time.time()\n",
    "    dataset = generator.Dataset()\n",
    "    train = dataset.train_generator\n",
    "    val = dataset.val_generator\n",
    "    epoch = val.epoch()\n",
    "    for i,(x,y) in tqdm(enumerate(epoch),total = val.steps_per_epoch):\n",
    "#         pass\n",
    "        return torch.as_tensor(x,device=torch.device('cuda')),torch.as_tensor(y,device=torch.device('cuda'))\n",
    "        \n",
    "    print(time.time() - temp)\n",
    "x,y = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "device = torch.device('cuda')\n",
    "a = torch.Tensor(x)\n",
    "b = torch.from_numpy(x)\n",
    "b[0,0] = 1000\n",
    "c = torch.as_tensor(x,device=device)\n",
    "# b = b.cuda()\n",
    "# print(a.dtype,b.dtype)\n",
    "# c.device\n",
    "# b.device\n",
    "# b.cuda()\n",
    "# c = torch.Tensor(2,3)\n",
    "# c.cuda()\n",
    "print(a,b,c)\n",
    "a = a.cuda()\n",
    "print(a)\n",
    "b = b.to(device)\n",
    "print(b)\n",
    "b[0,0] = 100\n",
    "c[0,0] = 100\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = np.random.randint(2, size = (2,3,128,128,128))\n",
    "# a = tf.constant(x,dtype = float)\n",
    "# with tf.Session() as s:\n",
    "#     print(dice_coefficient(a,a).eval())\n",
    "axis=(-1,-2,-3)\n",
    "smooth=0.00001\n",
    "#     temp = (2*K.sum(a * a, axis=axis) + smooth)/(K.sum(a, axis=axis) + K.sum(a,axis=axis) + smooth)\n",
    "#     print(temp.eval())\n",
    "#     print(K.mean(temp).eval())\n",
    "x = torch.as_tensor(a, device=torch.device('cuda'))\n",
    "xx = torch.as_tensor(a, device = torch.device('cpu'))\n",
    "import loss\n",
    "w_dice = loss.WeightedDiceLoss()\n",
    "w_dice(x, y).device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yml') as f:\n",
    "    config = yaml.load(f,Loader=yaml.FullLoader)\n",
    "    print(config['data'])\n",
    "with open('a.yml','w') as f:\n",
    "    yaml.dump({'a':[1,2,3]},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "class test():\n",
    "    def __init__(self):\n",
    "        self.h5_f = h5py.File('data/training.h5','r')\n",
    "    def hello(self):\n",
    "        print(len(list(self.h5_f.keys())))\n",
    "    def end(self):\n",
    "        self.h5_f.close()\n",
    "t = test()\n",
    "t.hello()\n",
    "t.end()\n",
    "t.__init__()\n",
    "t.hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# temp = time.time()\n",
    "# print(patching_autofit((240,240,155),(128,128,128)))\n",
    "# print(time.time()-temp)\n",
    "# temp = time.time()\n",
    "# print(patching_hardcode128((240,240,155),(128,128,128)))\n",
    "# print(time.time()-temp)\n",
    "# print(patching((240,240,155),(128,128,128)))\n",
    "\n",
    "# print(np.vstack((a,b)))\n",
    "print('\\n')\n",
    "print(patching((240,240,155),(128,128,128)))\n",
    "print('\\n')\n",
    "print(patching((240,240,155),(128,128,128),overlap=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float('inf') == float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array([8,6+12]) -18) % 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a':1,'b':2}\n",
    "with open('test.pkl','wb') as f:\n",
    "    pickle.dump(a,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/mean_std.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([1,2,3,50,34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([np.mean([1,34]),np.mean([2,3,50])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
